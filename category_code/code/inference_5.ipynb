{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/0q/2d61wl2n01168g5hgx5w5wd40000gn/T/ipykernel_3013/4139648825.py\", line 20, in <module>\n",
      "    results = model(img_li) # ì´ë¯¸ì§€ ëª¨ë¸ ì¶”ë¡  [1.jpg, 2.jpg ....]\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/ultralytics/engine/model.py\", line 110, in __call__\n",
      "    return self.predict(source, stream, **kwargs)\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/ultralytics/engine/model.py\", line 254, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/ultralytics/engine/predictor.py\", line 195, in __call__\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 35, in generator_context\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/ultralytics/engine/predictor.py\", line 227, in stream_inference\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/ultralytics/engine/predictor.py\", line 208, in setup_source\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/ultralytics/data/build.py\", line 150, in load_inference_source\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/ultralytics/data/build.py\", line 126, in check_source\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/ultralytics/data/loaders.py\", line 358, in autocast_list\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/PIL/Image.py\", line 3236, in open\n",
      "OSError: [Errno 24] Too many open files: '/Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images/511755.jpg'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1081, in get_records\n",
      "  File \"/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/pygments/styles/__init__.py\", line 89, in get_style_by_name\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 914, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1407, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1379, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1510, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1553, in _fill_cache\n",
      "OSError: [Errno 24] Too many open files: '/Users/young/miniforge3/envs/ml_project/lib/python3.8/site-packages/pygments/styles'\n"
     ]
    }
   ],
   "source": [
    "# from ultralytics import YOLO\n",
    "# import os\n",
    "# import argparse\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# label_dicts = {'íƒ‘':0, 'ë¸”ë¼ìš°ìŠ¤':1, 'í‹°ì…”ì¸ ':2, 'ë‹ˆíŠ¸ì›¨ì–´':3, 'ì…”ì¸ ':4, \n",
    "#          'ë¸Œë¼íƒ‘':5, 'í›„ë“œí‹°':6, 'ì²­ë°”ì§€':7, 'íŒ¬ì¸ ':8, 'ìŠ¤ì»¤íŠ¸':9, \n",
    "#          'ë ˆê¹…ìŠ¤':10, 'ì¡°ê±°íŒ¬ì¸ ':11, 'ì½”íŠ¸':12, 'ì¬í‚·':13, 'ì í¼':14, \n",
    "#          'íŒ¨ë”©':15, 'ë² ìŠ¤íŠ¸':16, 'ê°€ë””ê±´':17, 'ì§šì—…':18, 'ë“œë ˆìŠ¤':19, \n",
    "#          'ì í”„ìˆ˜íŠ¸':20}\n",
    "# reverse_label_dict= dict(map(reversed,label_dicts.items()))\n",
    "\n",
    "# pretrain_path = '/Users/young/Documents/zerobase/team_project/DL_project/model_project/runs/detect/train4_9-17/weights/best.pt'\n",
    "# result_path = '/Users/young/Documents/zerobase/team_project/DL_project/model_project/result'\n",
    "# valid_path = '/Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images'\n",
    "# img_li = [os.path.join(valid_path, f) for f in os.listdir(valid_path) if f != '.DS_Store'] \n",
    "\n",
    "# model = YOLO(pretrain_path)  # í”„ë¦¬íŠ¸ë ˆì¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# results = model(img_li) # ì´ë¯¸ì§€ ëª¨ë¸ ì¶”ë¡  [1.jpg, 2.jpg ....]\n",
    "\n",
    "# for i in range(len(img_li)):\n",
    "#     # res_plotted = results[i][0].plot() # ì¶”ë¡  ê²°ê³¼ë¥¼ ê·¸ë ¤ë³¼ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "#     res_plotted = results[i].plot()\n",
    "#     cv2.imwrite(os.path.join(result_path, img_li[i].split('/')[-1]), res_plotted) # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥\n",
    "\n",
    "#     boxes = results[i][0].boxes # ë°•ìŠ¤ ì¢Œí‘œì™€ í´ë˜ìŠ¤ì— ëŒ€í•œ ì •ë³´ ë³´ê´€ boxes.cls(í´ë˜ìŠ¤ ì •ë³´), boxes.xywh(bboxì¢Œí‘œ)\n",
    "#     cls = boxes.cls.cpu().tolist() # ê²°ê³¼ê°€ tensor í˜•íƒœë¡œ ë‚˜ì˜¨ê²ƒì„ íŒŒì´ì¬ì˜ ë¦¬ìŠ¤íŠ¸ ìë£Œí˜•ìœ¼ë¡œ ë³€í™˜\n",
    "#     print('inference result:' + reverse_label_dict[int(cls[0])]) # ì¶”ë¡ í•œ ê²°ê³¼ë¥¼ dictsì— ëŒ€ì…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # valid box image ìƒì„± ì½”ë“œ\n",
    "# from ultralytics import YOLO\n",
    "# import os\n",
    "# # import argparse\n",
    "# # import cv2\n",
    "# # import numpy as np\n",
    "\n",
    "# label_dicts = {'íƒ‘':0, 'ë¸”ë¼ìš°ìŠ¤':1, 'í‹°ì…”ì¸ ':2, 'ë‹ˆíŠ¸ì›¨ì–´':3, 'ì…”ì¸ ':4, \n",
    "#          'ë¸Œë¼íƒ‘':5, 'í›„ë“œí‹°':6, 'ì²­ë°”ì§€':7, 'íŒ¬ì¸ ':8, 'ìŠ¤ì»¤íŠ¸':9, \n",
    "#          'ë ˆê¹…ìŠ¤':10, 'ì¡°ê±°íŒ¬ì¸ ':11, 'ì½”íŠ¸':12, 'ì¬í‚·':13, 'ì í¼':14, \n",
    "#          'íŒ¨ë”©':15, 'ë² ìŠ¤íŠ¸':16, 'ê°€ë””ê±´':17, 'ì§šì—…':18, 'ë“œë ˆìŠ¤':19, \n",
    "#          'ì í”„ìˆ˜íŠ¸':20}\n",
    "# reverse_label_dict= dict(map(reversed,label_dicts.items()))\n",
    "\n",
    "# pretrain_path = '/Users/young/Documents/zerobase/team_project/DL_project/model_project/runs/detect/ct_train4/weights/best.pt'\n",
    "# result_path = '/Users/young/Documents/zerobase/team_project/DL_project/model_project/result'\n",
    "# valid_path = '/Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images'\n",
    "# img_li = [os.path.join(valid_path, f) for f in os.listdir(valid_path) if f != '.DS_Store'] \n",
    "\n",
    "# model = YOLO(pretrain_path)  # í”„ë¦¬íŠ¸ë ˆì¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# result = model.predict('/Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images', save=True, save_txt=True, imgsz=320, conf=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.137 ğŸš€ Python-3.8.16 torch-2.0.1 MPS (Apple M2 Pro)\n",
      "Model summary (fused): 168 layers, 3009743 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/young/Documents/zerobase/team_project/DL_project/model_proj\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images/172794.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0175]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images/240631.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0037]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images/256015.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0037]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images/68525.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.005]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING âš ï¸ /Users/young/Documents/zerobase/team_project/DL_project/model_project/dataset/valid/images/68569.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0063]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all      23201      33574        0.7      0.657      0.684      0.573\n",
      "                   Top      23201       1436        0.6      0.252       0.38      0.297\n",
      "                Blouse      23201       3204      0.681      0.827      0.815       0.69\n",
      "                Tshirt      23201       5102      0.697      0.784      0.807      0.678\n",
      "              KnitWear      23201       2062      0.617      0.712      0.715      0.614\n",
      "                 Shirt      23201       1473      0.615      0.683      0.688      0.577\n",
      "                BraTop      23201         40          1          0     0.0563     0.0388\n",
      "                Hoodie      23201        302       0.68      0.563      0.606      0.529\n",
      "                 Jeans      23201       3651      0.834      0.875      0.898      0.722\n",
      "                 Pants      23201       5296       0.83      0.889      0.909      0.727\n",
      "                 Skirt      23201       2859      0.849      0.906      0.932      0.754\n",
      "           JoggerPants      23201        177      0.635      0.542      0.577      0.465\n",
      "                  Coat      23201        792      0.715      0.759      0.814      0.726\n",
      "                Jacket      23201       1171      0.647      0.751       0.76      0.656\n",
      "                Jumper      23201        333      0.467      0.483      0.435      0.388\n",
      "          PaddedJacket      23201        171      0.715      0.819      0.835      0.725\n",
      "                  Vest      23201        421      0.674      0.781      0.729      0.562\n",
      "              Cardigan      23201        747      0.626       0.61      0.654      0.561\n",
      "             ZipJacket      23201        147      0.514      0.245      0.342      0.293\n",
      "                 Dress      23201       4060      0.895      0.952      0.969      0.851\n",
      "              JumpSuit      23201        130      0.701      0.703      0.754      0.615\n",
      "Speed: 0.3ms preprocess, 3.1ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Validate YOLOv8n on COCO128 val\n",
    "!yolo val model='/Users/young/Documents/zerobase/team_project/DL_project/model_project/runs/detect/ct_train6/weights/best.pt' data='/Users/young/Documents/zerobase/team_project/DL_project/model_project/config/category.yaml' device=mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
